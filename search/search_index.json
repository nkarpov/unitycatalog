{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#unity-catalog-open-multimodal-catalog-for-data-ai","title":"Unity Catalog: Open, Multimodal Catalog for Data &amp; AI","text":"<p>Unity Catalog is the industry\u2019s only universal catalog for data and AI.</p> <ul> <li>Multimodal interface supports any format, engine, and asset</li> <li>Multi-format support: It is extensible and supports Delta Lake, Apache Iceberg and Apache Hudi via UniForm, Apache Parquet, JSON, CSV, and many others.</li> <li>Multi-engine support: With its open APIs, data cataloged in Unity can be read by many leading compute engines.</li> <li>Multimodal: It supports all your data and AI assets, including tables, files, functions, AI models.</li> <li>Open source API and implementation - OpenAPI spec and OSS implementation (Apache 2.0 license). It is also compatible with Apache Hive's metastore API and Apache Iceberg's REST catalog API. Unity Catalog is currently a sandbox project with LF AI and Data Foundation (part of the Linux Foundation).</li> <li>Unified governance for data and AI - Govern and secure tabular data, unstructured assets, and AI assets with a single interface.</li> </ul> <p>The first release of Unity Catalog focuses on a core set of APIs for tables, unstructured data, and AI assets - with more to come soon on governance, access, and client interoperability. This is just the beginning!</p> <p></p> <p>Unity Catalog is proud to be hosted by the LF AI &amp; Data Foundation.</p> <p> </p>"},{"location":"deployment/","title":"Deployment","text":"<p>This guide outlines how to deploy the Unity Catalog server.</p>"},{"location":"deployment/#deploying-using-tarball","title":"Deploying using tarball","text":""},{"location":"deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>To generate the tarball, run the following command in the source code:   <code>sh   build/sbt createTarball</code></li> </ul>"},{"location":"deployment/#unpacking-the-tarball","title":"Unpacking the tarball","text":"<ul> <li>The tarball generated in the <code>target</code> directory can be unpacked using the following command:   <code>sh   tar -xvf unitycatalog-&lt;version&gt;.tar.gz</code></li> <li>Unpacking the tarball will create the following directory structure:   <code>unitycatalog-&lt;version&gt;   \u251c\u2500\u2500 bin   \u2502   \u251c\u2500\u2500 start-uc-server   \u2502   \u2514\u2500\u2500 uc   \u251c\u2500\u2500 etc   \u2502   \u251c\u2500\u2500 conf   \u2502   \u251c\u2500\u2500 data   \u2502   \u251c\u2500\u2500 db   \u2502   \u2514\u2500\u2500 logs   \u2514\u2500\u2500 jars</code></li> <li>The <code>bin</code> directory contains the scripts that you can use to start the UC server and run the CLI as explained in the tutorial section.</li> <li>The <code>etc</code> directory contains the configuration, data, database, and logs directories.</li> <li>The <code>jars</code> directory contains the jar files required to run the UC server.</li> </ul>"},{"location":"deployment/#configuring-the-uc-server","title":"Configuring the UC server","text":"<ul> <li>The UC server can be configured by modifying the files in <code>etc/conf/</code>. This includes properties related to logging, server environment and the s3 configuration.</li> <li>Setting the server environment to <code>dev</code> will use the local file system for storing the backend database whereas <code>test</code> will spin up an in-memory database.</li> <li>The <code>etc/data/</code> directory contains the data files that are used by the UC server. This includes the tables and volumes that are created.</li> <li>The <code>etc/db/</code> directory contains the backend database that is used by the UC server.</li> </ul>"},{"location":"tutorial/","title":"Tutorial","text":"<p>Let's take Unity Catalog for spin. In this tutorial, we are going to do the following:</p> <ul> <li>In one terminal, run the UC server.</li> <li>In another terminal, we will explore the contents of the UC server using the UC CLI,   which is an example UC connector provided to demonstrate how to use the UC SDK for various assets,   as well as provide a convenient way to explore the content of any UC server implementation.</li> </ul>"},{"location":"tutorial/#prerequisites","title":"Prerequisites","text":"<p>You have to ensure that your local environment has the following:</p> <ul> <li>Clone this repository.</li> <li>Ensure the <code>JAVA_HOME</code> environment variable your terminal is configured to point to JDK11+.</li> <li>Compile the project running <code>build/sbt package</code> in the repository root directory.</li> </ul>"},{"location":"tutorial/#run-the-uc-server","title":"Run the UC Server","text":"<p>In a terminal, in the cloned repository root directory, start the UC server.</p> <pre><code>bin/start-uc-server\n</code></pre> <p>For the rest of the steps, continue in a different terminal.</p>"},{"location":"tutorial/#list-the-catalogs-and-schemas-with-the-cli","title":"List the catalogs and schemas with the CLI","text":"<p>Unity Catalog stores all assets in a 3-level namespace:</p> <ol> <li>catalog</li> <li>schema</li> <li>assets like tables, volumes, functions, etc.</li> </ol> <p>The UC server is pre-populated with a few sample catalogs, schemas, Delta tables, etc.</p> <p>Let's start by listing the catalogs using the CLI.</p> <pre><code>bin/uc catalog list\n</code></pre> <p>You should see a catalog named <code>unity</code>. Let's see what's in this <code>unity</code> catalog (pun intended).</p> <pre><code>bin/uc schema list --catalog unity\n</code></pre> <p>You should see that there is a schema named <code>default</code>. To go deeper into the contents of this schema, you have to list different asset types separately. Let's start with tables.</p>"},{"location":"tutorial/#operate-on-delta-tables-with-the-cli","title":"Operate on Delta tables with the CLI","text":"<p>Let's list the tables.</p> <pre><code>bin/uc table list --catalog unity --schema default\n</code></pre> <p>You should see a few tables. Some details are truncated because of the nested nature of the data. To see all the content, you can add <code>--output jsonPretty</code> to any command.</p> <p>Next, let's get the metadata of one those tables.</p> <pre><code>bin/uc table get --full_name unity.default.numbers\n</code></pre> <p>You can see that it is a Delta table. Now, specifically for Delta tables, this CLI can print a snippet of the contents of a Delta table (powered by the Delta Kernel Java project). Let's try that.</p> <pre><code>bin/uc table read --full_name unity.default.numbers\n</code></pre> <p>Let's try creating a new table.</p> <pre><code>bin/uc table create --full_name unity.default.myTable --columns \"col1 int, col2 double\" --storage_location /tmp/uc/myTable\n</code></pre> <p>If you list the tables again, you should see this new table. Next, let's write to the table with some randomly generated data (again, powered by Delta Kernel Java] and read it back.</p> <pre><code>bin/uc table write --full_name unity.default.myTable\nbin/uc table read --full_name unity.default.myTable\n</code></pre>"},{"location":"tutorial/#apis-and-compatibility","title":"APIs and Compatibility","text":"<ul> <li>Open API specification: The Unity Catalog Rest API is documented here.</li> <li>Compatibility and stability: The APIs are currently evolving and should not be assumed to be stable.</li> </ul>"},{"location":"integrations/unity-catalog-daft/","title":"Unity Catalog Daft Integration","text":"<p>This page shows you how to use Unity Catalog with Daft.</p> <p>Daft is a library for parallel and distributed processing of multimodal data.</p>"},{"location":"integrations/unity-catalog-daft/#set-up","title":"Set up","text":"<p>To start, install Daft with the extra Unity Catalog dependencies using:</p> <pre><code>pip install -U \"getdaft[unity]\"\n</code></pre> <p>Then import Daft and the <code>UnityCatalog</code> abstraction:</p> <pre><code>import daft\nfrom daft.unity_catalog import UnityCatalog\n</code></pre> <p>You need to have a Unity Catalog server running to connect to.</p> <p>For testing purposes, you can spin up a local server by running the code below in a terminal:</p> <pre><code>bin/start-uc-server\n</code></pre>"},{"location":"integrations/unity-catalog-daft/#connect-daft-to-unity-catalog","title":"Connect Daft to Unity Catalog","text":"<p>Use the <code>UnityCatalog</code> abstraction to point Daft to your UC server.</p> <p>This object requires an <code>endpoint</code> and a <code>token</code>. If you launched the UC server locally using the command above then you can use the values below. Otherwise substitute the <code>endpoint</code> and <code>token</code> values with the corresponding values for your UC server.</p> <pre><code># point Daft to your UC server\nunity = UnityCatalog(\n    endpoint=\"http://127.0.0.1:8080\",\n    token=\"not-used\",\n)\n</code></pre> <p>You can also connect to a Unity Catalog in your Databricks workspace by setting <code>endpoint = \"https://&lt;databricks_workspace_id&gt;.cloud.databricks.com\"</code>.</p> <p>Once you're connected, you can list all your available catalogs using:</p> <pre><code>&gt; print(unity.list_catalogs())\n['unity']\n</code></pre> <p>You can list all available schemas in a given catalog:</p> <pre><code>&gt; print(unity.list_schemas(\"unity\"))\n['unity.default']\n</code></pre> <p>And you can list all the available tables in a given schema:</p> <pre><code>print(unity.list_tables(\"unity.default\"))\n['unity.default.numbers', 'unity.default.marksheet_uniform', 'unity.default.marksheet']\n</code></pre>"},{"location":"integrations/unity-catalog-daft/#load-unity-tables-into-daft-dataframe","title":"Load Unity Tables into Daft DataFrame","text":"<p>You can use Daft to read Delta Lake tables in a Unity Catalog.</p> <p>First, point Daft to your Delta table stored in your Unity Catalog:</p> <pre><code>unity_table = unity.load_table(\"unity.default.numbers\")\n</code></pre> <p>Unity Catalog tables are stored in the Delta Lake format.</p> <p>Simply read your table using the Daft <code>read_delta_lake</code> method:</p> <pre><code>&gt; df = daft.read_delta_lake(unity_table)\n&gt; df.show()\n\nas_int  as_double\n564     188.755356\n755     883.610563\n644     203.439559\n75      277.880219\n42      403.857969\n680     797.691220\n821     767.799854\n484     344.003740\n477     380.678561\n131     35.443732\n294     209.322436\n150     329.197303\n539     425.661029\n247     477.742227\n958     509.371273\n</code></pre> <p>Any subsequent filter operations on the Daft <code>df</code> DataFrame object will be correctly optimized to take advantage of Delta Lake features.</p> <pre><code>&gt; df = df.where(df[\"as_int\"] &gt; 500)\n&gt; df.show()\n\nas_int   as_double\n564      188.755356\n755      883.610563\n644      203.439559\n680      797.691220\n821      767.799854\n539      425.661029\n958      509.371273\n</code></pre> <p>Daft support for Unity Catalog is under rapid development. Refer to the Daft documentation for more information.</p>"},{"location":"integrations/unity-catalog-duckdb/","title":"Unity Catalog DuckDB Integration","text":""},{"location":"integrations/unity-catalog-duckdb/#operate-on-delta-tables-with-duckdb","title":"Operate on Delta tables with DuckDB","text":"<p>To try operating on Delta tables with DuckDB, you will have to install it (at least version 1.0).</p> <p>Let's start DuckDB and install a couple of extensions. To start DuckDB, run the command <code>duckdb</code> in the terminal.</p> <p>Then, in the DuckDB shell, run the following commands:</p> <pre><code>install uc_catalog from core_nightly;\nload uc_catalog;\ninstall delta;\nload delta;\n</code></pre> <p>If you have installed these extensions before, you may have to run <code>update extensions</code> and restart DuckDB for the following steps to work.</p> <p>Now that we have DuckDB all set up, let's try connecting to UC by specifying a secret.</p> <pre><code>CREATE SECRET (\n      TYPE UC,\n      TOKEN 'not-used',\n      ENDPOINT 'http://127.0.0.1:8080',\n      AWS_REGION 'us-east-2'\n );\n</code></pre> <p>You should see it print a short table saying <code>Success</code> = <code>true</code>. Next we can attach the <code>unity</code> catalog to DuckDB.</p> <pre><code>ATTACH 'unity' AS unity (TYPE UC_CATALOG);\n</code></pre> <p>Now we are ready to query. Try the following</p> <pre><code>SHOW ALL TABLES;\nSELECT * from unity.default.numbers;\n</code></pre> <p>You should see the tables listed and the contents of the <code>numbers</code> table printed. To quit DuckDB, run the command <code>Ctrl+D</code> or type <code>.exit</code> in the DuckDB shell.</p>"},{"location":"integrations/unity-catalog-trino/","title":"Unity Catalog Trino Integration","text":""},{"location":"integrations/unity-catalog-trino/#setting-up-rest-catalog-with-trino","title":"Setting up REST Catalog with Trino","text":"<p>After setting up Trino, REST Catalog connection can be setup by adding a <code>etc/catalog/iceberg.properties</code> file to configure Trino to use Unity Catalog's Iceberg REST API Catalog endpoint.</p> <pre><code>connector.name=iceberg\niceberg.catalog.type=rest\niceberg.rest-catalog.uri=http://127.0.0.1:8080/api/2.1/unity-catalog/iceberg\niceberg.rest-catalog.security=OAUTH2\niceberg.rest-catalog.oauth2.token=not_used\n</code></pre> <p>Once your properties file is configured, you can run the Trino CLI and issue a SQL query against the Delta UniForm table:</p> <pre><code>SELECT * FROM iceberg.\"unity.default\".marksheet_uniform\n</code></pre>"},{"location":"usage/cli/","title":"Unity Catalog CLI","text":""},{"location":"usage/cli/#introduction","title":"Introduction","text":"<p>This CLI tool allows users to interact with a Unity Catalog server to create and manage catalogs, schemas, tables across different formats (DELTA, UNIFORM, PARQUET, JSON, and CSV), volumes with unstructured data, and functions.</p> <p>The Unity Catalog server can be a standalone server (see the server guide for how to start one), or simply configure the CLI to interface with Databricks Unity Catalog.</p>"},{"location":"usage/cli/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Catalog Management CLI Usage</li> <li>Schema Management CLI Usage</li> <li>Table Management CLI Usage</li> <li>Volume Management CLI Usage</li> <li>Function Management CLI Usage</li> </ol>"},{"location":"usage/cli/#catalog-management-cli-usage","title":"Catalog Management CLI Usage","text":"<p>This section outlines the usage of the <code>bin/uc</code> script for managing catalogs within your system.  The script supports various operations such as creating, retrieving, listing and updating catalogs.</p>"},{"location":"usage/cli/#list-catalogs","title":"List Catalogs","text":"<pre><code>bin/uc catalog list\n</code></pre>"},{"location":"usage/cli/#get-details-of-a-catalog","title":"Get details of a Catalog","text":"<pre><code>bin/uc catalog get --name &lt;name&gt; \n</code></pre> <ul> <li><code>name</code> : The name of the catalog.</li> </ul>"},{"location":"usage/cli/#create-a-catalog","title":"Create a Catalog","text":"<pre><code>bin/uc catalog create --name &lt;name&gt; [--comment &lt;comment&gt;]\n</code></pre> <ul> <li><code>name</code>: The name of the catalog.</li> <li><code>comment</code>: [Optional] The description of the catalog.</li> </ul> <p>Example: </p> <pre><code>bin/uc catalog create --name my_catalog --comment \"My First Catalog\"\n</code></pre>"},{"location":"usage/cli/#update-a-catalog","title":"Update a Catalog","text":"<pre><code>bin/uc catalog update --name &lt;name&gt; --new_name &lt;new_name&gt; [--comment &lt;comment&gt;]\n</code></pre> <ul> <li><code>name</code> : The name of the existing catalog.</li> <li><code>new_name</code> : The new name of the catalog.</li> <li><code>comment</code> : [Optional] The new description of the catalog.</li> </ul> <p>Example:</p> <pre><code>bin/uc catalog update --name my_catalog --new_name my_updated_catalog --comment \"Updated Catalog\"\n</code></pre>"},{"location":"usage/cli/#delete-a-catalog","title":"Delete a Catalog","text":"<pre><code>bin/uc catalog delete --name &lt;name&gt;\n</code></pre> <ul> <li><code>name</code> : The name of the catalog.</li> </ul>"},{"location":"usage/cli/#schema-management-cli-usage","title":"Schema Management CLI Usage","text":"<p>This section outlines the usage of the <code>bin/uc</code> script for managing schemas within your system.  The script supports various operations such as creating, retrieving, listing, updating and deleting schemas.</p>"},{"location":"usage/cli/#list-schemas","title":"List Schemas","text":"<pre><code>bin/uc schema list --catalog &lt;catalog&gt; [--max_results &lt;max_results&gt;]\n</code></pre> <ul> <li><code>catalog</code>: The name of the catalog.</li> <li><code>max_results</code>: [Optional] The maximum number of results to return.</li> </ul>"},{"location":"usage/cli/#get-a-schema","title":"Get a Schema","text":"<p>Retrieve the details of a schema using the full name of the schema.</p> <pre><code>bin/uc schema get --full_name &lt;catalog&gt;.&lt;schema&gt;\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> </ul>"},{"location":"usage/cli/#create-a-schema","title":"Create a Schema","text":"<pre><code>bin/uc schema create --catalog &lt;catalog&gt; --name &lt;name&gt; [--comment &lt;comment&gt;]\n</code></pre> <ul> <li><code>catalog</code>: The name of the catalog.</li> <li><code>name</code>: The name of the schema.</li> <li><code>comment</code>: [Optional]  The description of the schema.</li> </ul> <p>Example:</p> <pre><code>bin/uc schema create --catalog my_catalog --name my_schema --comment \"My Schema\"\n</code></pre>"},{"location":"usage/cli/#update-a-schema","title":"Update a Schema","text":"<pre><code>bin/uc schema update --full_name &lt;full_name&gt; --new_name &lt;new_name&gt; [--comment &lt;comment&gt;]\n</code></pre> <ul> <li><code>full_name</code>: The full name of the existing schema. The full name is the concatenation of the catalog name and schema name separated by a dot (e.g., <code>catalog_name.schema_name</code>).</li> <li><code>new_name</code>: The new name of the schema.</li> <li><code>comment</code>: [Optional] The new description of the schema.</li> </ul> <p>Example:</p> <pre><code>bin/uc schema update --full_name my_catalog.my_schema --new_name my_updated_schema --comment \"Updated Schema\"\n</code></pre>"},{"location":"usage/cli/#delete-a-schema","title":"Delete a Schema","text":"<pre><code>bin/uc schema delete --full_name &lt;catalog&gt;.&lt;schema&gt;\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> </ul>"},{"location":"usage/cli/#table-management-cli-usage","title":"Table Management CLI Usage","text":"<p>This section outlines the usage of the <code>bin/uc</code> script for managing tables within your system.  The script supports various operations such as creating, retrieving, listing and deleting tables.  There's additional functionality to write sample data to a DELTA table and read data from a DELTA table.</p>"},{"location":"usage/cli/#list-tables","title":"List Tables","text":"<pre><code>bin/uc table list --catalog &lt;catalog&gt; --schema &lt;schema&gt; [--max_results &lt;max_results&gt;]\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>max_results</code> [Optional] : The maximum number of results to return.</li> </ul>"},{"location":"usage/cli/#retrieve-table-information","title":"Retrieve Table Information","text":"<pre><code>bin/uc table get --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;table&gt;\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>table</code> : The name of the table.</li> </ul>"},{"location":"usage/cli/#create-a-table","title":"Create a Table","text":"<pre><code>bin/uc table create --full_name &lt;full_name&gt; --columns &lt;columns&gt; --storage_location &lt;storage_location&gt; [--format &lt;format&gt;] [--properties &lt;properties&gt;]\n</code></pre> <ul> <li><code>full_name</code>: The full name of the table, which is a concatenation of the catalog name,    schema name, and table name separated by dots (e.g., <code>catalog_name.schema_name.table_name</code>).</li> <li><code>columns</code>: The columns of the table in SQL-like format <code>\"column_name column_data_type\"</code>.   Supported data types include <code>BOOLEAN</code>, <code>BYTE</code>, <code>SHORT</code>, <code>INT</code>, <code>LONG</code>, <code>FLOAT</code>, <code>DOUBLE</code>, <code>DATE</code>, <code>TIMESTAMP</code>,   <code>TIMESTAMP_NTZ</code>, <code>STRING</code>, <code>BINARY</code>, <code>DECIMAL</code>. Separate multiple columns with a comma   (e.g., <code>\"id INT, name STRING\"</code>).</li> <li><code>format</code>: [Optional] The format of the data source. Supported values are <code>DELTA</code>, <code>PARQUET</code>, <code>ORC</code>, <code>JSON</code>, <code>CSV</code>, <code>AVRO</code>, and <code>TEXT</code>.  If not specified the default format is <code>DELTA</code>.</li> <li><code>storage_location</code>: The storage location associated with the table. It is a mandatory field for <code>EXTERNAL</code> tables.</li> <li><code>properties</code>:  [Optional] The properties of the entity in JSON format (e.g., <code>'{\"key1\": \"value1\", \"key2\": \"value2\"}'</code>).  Make sure to either escape the double quotes(<code>\\\"</code>) inside the properties string or just use single quotes(<code>''</code>) around the same.</li> </ul> <p>Example:</p> <ul> <li>Create an external DELTA table with columns <code>id</code> and <code>name</code> in the schema <code>my_schema</code> of catalog <code>my_catalog</code> with storage location <code>/path/to/storage</code>:</li> </ul> <pre><code>bin/uc table create --full_name my_catalog.my_schema.my_table --columns \"id INT, name STRING\" --storage_location \"/path/to/storage\"\n</code></pre> <p>When running against UC OSS server, the storage location can be a local path(absolute path) or an S3 path. When S3 path is provided,  the server will vend temporary credentials to access the S3 bucket and server properties must be set up accordingly. When running against Databricks Unity Catalog, the storage location for EXTERNAL table can only be an S3 location which has been configured as an <code>external location</code> in your Databricks workspace.</p>"},{"location":"usage/cli/#read-a-delta-table","title":"Read a DELTA Table","text":"<pre><code>bin/uc table read --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;table&gt; [--max_results &lt;max_results&gt;]\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>table</code> : The name of the table.</li> <li><code>max_results</code> : [Optional] The maximum number of rows to return.</li> </ul>"},{"location":"usage/cli/#write-sample-data-to-a-delta-table","title":"Write Sample Data to a DELTA Table","text":"<pre><code>bin/uc table write --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;table&gt;\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>table</code> : The name of the table.</li> </ul> <p>This is an experimental feature and only some primitive types are supported for writing sample data.</p>"},{"location":"usage/cli/#delete-a-table","title":"Delete a Table","text":"<pre><code>bin/uc table delete --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;table&gt;\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>table</code> : The name of the table.</li> </ul>"},{"location":"usage/cli/#volume-management-cli-usage","title":"Volume Management CLI Usage","text":"<p>This section outlines the usage of the <code>bin/uc</code> script for managing volumes within your system.  The script supports various operations such as creating, retrieving, listing and deleting volumes.</p>"},{"location":"usage/cli/#list-volumes","title":"List Volumes","text":"<pre><code>bin/uc volume list --catalog &lt;catalog&gt; --schema &lt;schema&gt; [--max_results &lt;max_results&gt;]\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>max_results</code> : [Optional] The maximum number of results to return.</li> </ul>"},{"location":"usage/cli/#retrieve-volume-information","title":"Retrieve Volume Information","text":"<pre><code>bin/uc volume get --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;volume&gt;\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.  </li> <li><code>schema</code> : The name of the schema.</li> <li><code>volume</code> : The name of the volume.</li> </ul>"},{"location":"usage/cli/#create-a-volume","title":"Create a Volume","text":"<pre><code>bin/uc volume create --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;volume&gt; --storage_location &lt;storage_location&gt; [--comment &lt;comment&gt;]\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>volume</code> : The name of the volume.</li> <li><code>storage_location</code> : The storage location associated with the volume. When running against UC OSS server,  the storage location can be a local path(absolute path) or an S3 path. When S3 path is provided, the server will vend temporary credentials to access the S3 bucket and server properties must be set up accordingly. When running against Databricks Unity Catalog, the storage location for EXTERNAL volume can only be an S3 location which has been configured as an <code>external location</code> in your Databricks workspace.</li> <li><code>comment</code> : [Optional] The description of the volume.</li> </ul> <p>Example: * Create an external volume with full name <code>my_catalog.my_schema.my_volume</code> with storage location <code>/path/to/storage</code> :</p> <pre><code>bin/uc volume create --full_name my_catalog.my_schema.my_volume --storage_location \"/path/to/storage\"\n</code></pre>"},{"location":"usage/cli/#update-a-volume","title":"Update a Volume","text":"<pre><code>bin/uc volume update --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;volume&gt; --new_name &lt;new_name&gt; [--comment &lt;comment&gt;]\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>volume</code> : The name of the volume.</li> <li><code>new_name</code> : The new name of the volume.</li> <li><code>comment</code> : [Optional] The new description of the volume.</li> </ul> <p>Example:</p> <pre><code>bin/uc volume update --full_name my_catalog.my_schema.my_volume --new_name my_updated_volume --comment \"Updated Volume\"\n</code></pre>"},{"location":"usage/cli/#read-a-volumes-content","title":"Read a Volume's content","text":"<pre><code>bin/uc volume read --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;volume&gt; [--path &lt;path&gt;]\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>volume</code> : The name of the volume.</li> <li><code>path</code> : [Optional] The path relative to the volume root.  If no path is provided, the volume root is read. If the final path is a directory, the contents of the directory are listed(ls).  If the final path is a file, the contents of the file are displayed(cat).</li> </ul>"},{"location":"usage/cli/#write-sample-data-to-a-volume","title":"Write Sample Data to a Volume","text":"<pre><code>bin/uc volume write --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;volume&gt;\n</code></pre> <p>Writes sample txt data to a randomly generated file name(UUID) in the volume. This is an experimental feature.</p> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>volume</code> : The name of the volume.</li> </ul>"},{"location":"usage/cli/#delete-a-volume","title":"Delete a Volume","text":"<pre><code>bin/uc volume delete --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;volume&gt;\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>volume</code> : The name of the volume. </li> </ul>"},{"location":"usage/cli/#function-management-cli-usage","title":"Function Management CLI Usage","text":"<p>This section outlines the usage of the <code>bin/uc</code> script for managing functions within your catalog.  The script supports various operations such as creating, retrieving, listing and deleting functions.</p>"},{"location":"usage/cli/#list-functions","title":"List Functions","text":"<pre><code>bin/uc function list --catalog &lt;catalog&gt; --schema &lt;schema&gt; [--max_results &lt;max_results&gt;]\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>max_results</code> : [Optional] The maximum number of results to return.</li> </ul>"},{"location":"usage/cli/#retrieve-function-information","title":"Retrieve Function Information","text":"<pre><code>bin/uc function get --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;function_name&gt;\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>function_name</code> : The name of the function.</li> </ul>"},{"location":"usage/cli/#create-a-function","title":"Create a Function","text":"<pre><code>bin/uc function create --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;function_name&gt; --input_params &lt;input_params&gt; --data_type &lt;data_type&gt; --def &lt;definition&gt; [--comment &lt;comment&gt;] [--language &lt;language&gt;]\n</code></pre> <ul> <li><code>full_name</code>: The full name of the function, which is a concatenation of the catalog name, schema name, and function name separated by dots (e.g., <code>catalog_name.schema_name.function_name</code>).</li> <li><code>input_params</code> : The input parameters to the function in SQL-like format <code>\"param_name param_data_type\"</code>. Multiple input parameters should be separated by a comma (e.g., <code>\"param1 INT, param2 STRING\"</code>).</li> <li><code>data_type</code>: The data type of the function. Either a type_name(for e.g. <code>INT</code>,<code>DOUBLE</code>, <code>BOOLEAN</code>, <code>DATE</code>), or <code>TABLE_TYPE</code> if this is a table valued function.</li> <li><code>def</code>: The definition of the function. The definition should be a valid SQL statement or a python routine with the function logic and return statement.</li> <li><code>comment</code>: [Optional] The description of the function.</li> <li><code>language</code>: [Optional]  The language of the function. If not specified, the default value is <code>PYTHON</code>.</li> </ul> <p>Example: Create a python function that takes two integer inputs and returns the sum of the inputs:</p> <pre><code>bin/uc function create --full_name my_catalog.my_schema.my_function --input_params \"param1 INT, param2 INT\" --data_type INT --def \"return param1 + param2\" --comment \"Sum Function\"\n</code></pre>"},{"location":"usage/cli/#invoke-a-function","title":"Invoke a Function","text":"<pre><code>bin/uc function call --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;function_name&gt; --input_params &lt;input_params&gt;\n</code></pre> <ul> <li><code>full_name</code>: The full name of the function, which is a concatenation of the catalog name, schema name, and function name separated by dots (e.g., <code>catalog_name.schema_name.function_name</code>).</li> <li><code>input_params</code> : The value of input parameters to the function separated by a comma (e.g., <code>\"param1,param2\"</code>).</li> </ul> <p>This is an experimental feature and only supported for python functions that take in primitive types as input parameters. It runs the functions using the python engine script at <code>etc/data/function/python_engine.py</code>.</p> <p>Example: Invoke a python sum function that takes two integer inputs:</p> <pre><code>bin/uc function call --full_name my_catalog.my_schema.my_function --input_params \"1,2\"\n</code></pre>"},{"location":"usage/cli/#delete-a-function","title":"Delete a Function","text":"<pre><code>bin/uc function delete --full_name &lt;catalog&gt;.&lt;schema&gt;.&lt;function_name&gt;\n</code></pre> <ul> <li><code>catalog</code> : The name of the catalog.</li> <li><code>schema</code> : The name of the schema.</li> <li><code>function_name</code> : The name of the function.</li> </ul>"},{"location":"usage/cli/#server-configuration","title":"Server Configuration","text":"<p>By default, the CLI tool is configured to interact with a local reference server running at <code>http://localhost:8080</code>. The CLI can be configured to talk to Databricks Unity Catalog by one of the following methods:</p> <ul> <li>Include the following params in CLI commands:<ul> <li><code>--server &lt;server_url&gt;</code>: The URL of the Unity Catalog server.</li> <li><code>--auth_token &lt;auth_token&gt;</code>: The PAT(Personal Authorization Token) token obtained from Databricks' Workspace.</li> </ul> </li> <li>Set the following properties in the CLI configuration file located at <code>examples/cli/src/main/resources/application.properties</code>:<ul> <li><code>server</code>: The URL of the Unity Catalog server.</li> <li><code>auth_token</code>: The PAT(Personal Authorization Token) token obtained from Databricks' Workspace.</li> </ul> </li> </ul> <p>Each parameter can be configured either from the CLI or the configuration file, independently of each other. The CLI will prioritize the values provided from the CLI over the configuration file.</p>"},{"location":"usage/functions/","title":"Unity Catalog Functions","text":"<p>Let's list the functions.</p> <pre><code>bin/uc function list --catalog unity --schema default\n</code></pre> <p>You should see a few functions. Let's get the metadata of one of these functions.</p> <pre><code>bin/uc function get --full_name unity.default.sum\n</code></pre> <p>In the printed metadata, pay attention to the columns <code>input_parameters</code>, <code>external_language</code>, and <code>routine_definition</code>.</p> <p>This seems like a simple python function that takes 3 arguments and returns the sum of them. Let's try calling this function.</p> <p>Behind the scenes, the invocation of the function is achieved by calling the python script at <code>etc/data/function/python_engine.py</code> with the function name and arguments.</p> <pre><code>bin/uc function call --full_name unity.default.sum --input_params \"1,2,3\"\n</code></pre> <p>Voila! You have called a function stored in UC. Let's try and create a new function.</p> <pre><code>bin/uc function create --full_name unity.default.myFunction --data_type INT --input_params \"a int, b int\" --def \"c=a*b\\nreturn c\"\n</code></pre> <p>You can test out the newly created function by invoking it.</p> <pre><code>bin/uc function call --full_name unity.default.myFunction --input_params \"2,3\"\n</code></pre> <p>You should see the result is 6.</p>"},{"location":"usage/server/","title":"Unity Catalog Server","text":"<p>This is the open source version of the Unity Catalog server implementation. It can be started locally for local usage (e.g. for testing) without any Databricks account.</p>"},{"location":"usage/server/#running-the-server","title":"Running the Server","text":"<p>The server can be started by issuing the below command from the project root directory:</p> <pre><code>bin/start-uc-server\n</code></pre>"},{"location":"usage/server/#configuration","title":"Configuration","text":"<p>The server config file is at the location <code>etc/conf/server.properties</code> (relative to the project root).</p> <ul> <li><code>server.env</code>: The environment in which the server is running. This can be set to <code>dev</code> or <code>test</code>. When set to <code>test</code> the server will instantiate an empty in-memory h2 database for storing metadata. If set to <code>dev</code>, the server will use the file <code>etc/db/h2db.mv.db</code> as the metadata store. Any changes made to the metadata will be persisted in this file.</li> </ul> <p>For enabling server to vend AWS temporary credentials to access S3 buckets (for accessing External tables/volumes), the following parameters need to be set:</p> <ul> <li><code>s3.bucketPath.i</code>: The S3 path of the bucket where the data is stored. Should be in the format <code>s3://&lt;bucket-name&gt;</code>.</li> <li><code>s3.accessKey.i</code>: The AWS access key, an identifier of temp credentials.</li> <li><code>s3.secretKey.i</code>: The AWS secret key used to sign API requests to AWS.</li> <li><code>s3.sessionToken.i</code>: THE AWS session token, used to verify that the request is coming from a trusted source.</li> </ul> <p>You can configure multiple buckets by incrementing the index i in the above parameters. The starting index should be 0.</p> <p>All the above parameters are required for each index. For vending temporary credentials, the server matches the bucket path in the table/volume storage_location with the bucket path in the configuration and returns the corresponding access key, secret key, and session token.</p> <p>Any params that are not required can be left empty.</p>"},{"location":"usage/server/#logging","title":"Logging","text":"<p>The server logs are located at <code>etc/logs/server.log</code>. The log level and log rolling policy can be set in log4j2 config file: <code>etc/conf/server.log4j2.properties</code></p>"},{"location":"usage/volumes/","title":"Unity Catalog Volumes","text":"<p>Let's list the volumes.</p> <pre><code>bin/uc volume list --catalog unity --schema default\n</code></pre> <p>You should see a few volumes. Let's get the metadata of one of those volumes.</p> <pre><code>bin/uc volume get --full_name unity.default.json_files\n</code></pre> <p>Now let's list the directories/files in this volume.</p> <pre><code>bin/uc volume read --full_name unity.default.json_files\n</code></pre> <p>You should see two text files listed and one directory. Let's read the content of one of those files.</p> <pre><code>bin/uc volume read --full_name unity.default.json_files --path c.json\n</code></pre> <p>Voila! You have read the content of a file stored in a volume. We can also list the contents of any subdirectory. For example:</p> <pre><code>bin/uc volume read --full_name unity.default.json_files --path dir1\n</code></pre> <p>Now let's try creating a new external volume. First physically create a directory with some files in it. For example, create a directory <code>/tmp/myVolume</code> and put some files in it. Then create the volume in UC.</p> <pre><code>bin/uc volume create --full_name unity.default.myVolume --storage_location /tmp/myVolume\n</code></pre> <p>Now you can see the contents of this volume.</p> <pre><code>bin/uc volume read --full_name unity.default.myVolume\n</code></pre>"},{"location":"usage/tables/uniform/","title":"Unity Catalog with UniForm tables","text":""},{"location":"usage/tables/uniform/#read-delta-uniform-tables-via-iceberg-rest-catalog","title":"Read Delta Uniform tables via Iceberg REST Catalog","text":"<p>Delta Tables with Uniform enabled can be accessed via Iceberg REST Catalog. The Iceberg REST Catalog is served at <code>http://127.0.0.1:8080/api/2.1/unity-catalog/iceberg/</code>.</p> <p>A pre-populated Delta Uniform table can be prepared by running <code>cp -r etc/data/external/unity/default/tables/marksheet_uniform /tmp/marksheet_uniform</code>.</p>"},{"location":"usage/tables/uniform/#setting-up-rest-catalog-with-apache-spark","title":"Setting up REST Catalog with Apache Spark","text":"<p>The following is an example of the settings to configure OSS Apache Spark to read UniForm as Iceberg:</p> <pre><code>\"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n\"spark.sql.catalog.iceberg\": \"org.apache.iceberg.spark.SparkCatalog\",\n\"spark.sql.catalog.iceberg.catalog-impl\": \"org.apache.iceberg.rest.RESTCatalog\",\n\"spark.sql.catalog.iceberg.uri\": \"http://127.0.0.1:8080/api/2.1/unity-catalog/iceberg\",\n\"spark.sql.catalog.iceberg.token\": \"not_used\",\n</code></pre> <p>When querying Iceberg REST Catalog for Unity Catalog, tables are identified using the following pattern <code>iceberg.&lt;catalog-name&gt;.&lt;schema-name&gt;.&lt;table-name&gt;</code> (e.g. <code>iceberg.unity.default.marksheet_uniform</code>).</p>"}]}